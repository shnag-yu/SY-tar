# 2022DS-PJ-开发文档
## 代码结构概要
类的声明写在`include`文件夹下的`.h`文件中；
类的实现写在`src`文件夹下的`.cpp`文件中。
+ node类
  
    Huffman树的结点。储存字节编号，字节频率，字节的Huffman编码，以及左右儿子的指针。
+ huffman类

    Huffman树。储存Huffman树的根节点。
    提供
    
    + 通过结点数组生成Huffman树
    + 以及字节对应的Huffman编码的方法。
+ comp类

    通过Huffman编码算法压缩文件。
    提供
    + 从源文件中读取数据
    + 通过字节频率建立Huffman树
    + 写压缩文件头部信息
    + 通过Huffman编码写压缩文件正文的方法。
    
+ uncomp类

    通过压缩文件的头部文件还原Huffman树从而解压缩文件。
    提供
    + 从压缩文件读取头部信息
    + 从压缩文件读取主体信息
    + 通过读取到的字节频率构建Huffman树和Huffman编码
    + 还原源文件

+ dirComp类

    用于压缩文件夹。
    提供
    + 通过递归遍历文件夹利用`comp`类来压缩文件夹的方法

+ dirUmcomp类

    用于解压缩文件夹压缩文件。
    引入
    + `entry`结构体
        表示文件夹内部的路径条目
        提供
    + 通过压缩文件数据流构建文件树并遍历
    + 利用`uncomp`类递归解压压缩文件的方法

## 项目需求的实现
### 文件的压缩与解压
+ 文件的压缩
    + 基本思路：
        1. 对于文件头部信息：按二进制逐字节扫一遍原文件，将原文件的文件名，文件名长度，字节总数，字节种类，字节频率数组写入头部信息。
        2. 对于文件主体数据：通过字节频率建立Huffman树，获得Huffman编码，再将文件正文逐字节按照Huffman编码映射改写，从而达到压缩的目的。
    + 特殊情况：
        对于空文件的情况，即读到字节总数为零时，跳过写压缩文件主体的过程，只写头部信息。
+ 文件的解压
    + 基本思路：
        1. 先读入压缩文件头部信息，根据字节频率构建Huffman树，获得Huffman编码。
        2. 根据头部信息内的原文件名初始化文件输出流。保证解压后文件名不变。
        3. 逐字节读压缩文件正文，根据Huffman编码还原。
    + 特殊情况：
        对于空文件生成的压缩文件，读到字节总数为零时，仅根据原文件名初始化一个空文件。
### 文件夹的压缩与解压
+ 文件夹的压缩
    + 基本思路：
        1. 通过`filesystem`递归遍历文件夹，将遍历到的路径（无论文件夹或文件）写入压缩文件
        2. 每次遍历到文件时，利用`comp`类将该压缩文件的信息写入压缩文件
    + 特殊情况：
        不需要特殊考虑空文件夹的情况.
+ 文件夹的解压
    + 基本思路：
        1. 先创建父文件夹。
        2. 遍历压缩文件流，读到路径提示符时（我设置了`(char)255`作为路径提示符）以path类读入下一段信息，如果读入信息是路径的话，通过路径后紧接着的路径类型提示符（我设置了`(char)254(char)254`作为文件类型提示符）判断路径表示的是文件或者文件夹并分别处理。如果读入信息不是文件路径，就继续寻找下一个文件提示符。
        3. 路径表示文件夹，就创建该文件夹。
        4. 路径表示文件，就利用`uncomp`类解压。
    + 特殊情况
        不需要特殊考虑原文件为空文件夹的情况。
### CLI交互
通过命令行参数解析出指令类型以及指令对象。
设计的命令行指令语法为：
```
>>> ./main (指令类型) (指令源对象) (指令目标对象)  //指令目标对象可选。
```
`main`程序通过命令行参数指示工作模式:

`comp`：压缩、`uncomp`：解压、`display`：展示原文件结构.

示例如下。

+ `comp` 
  
    ```
    >>> ./main comp source dest
    ```
    将被压缩对象`source`（可以是文件或者文件夹）压缩到压缩文件`dest`中。
+ `uncomp`

    ```
    >>> ./main uncomp source
    ```
    将由SY-tar程序压缩的压缩文件`source`解压到当前目录。
+ `display`
  
    ```
    >>> ./main display source
    ```
    在不解压压缩文件的情况下展示原文件（文件夹）的结构。
### 检验压缩包来源是否是自己的压缩⼯具 
在压缩文件头部信息最前部分写入标记headTag。

原文件为文件: headTag = "Produced By SY Compress Program."

原文件为文件夹: headTag = "produced By SY Compress Program." 

每次试图解压前先检查headTag。若headTag不等于上述字符串，输出`"This is NOT produced by my program!"`，并直接退出。
### 文件覆盖问题

设计一个函数`int isInCurDir(std::string filename);`

用于通过`std::filesystem`提供的方法遍历当前目录，并判断`filename`对应的文件或文件夹是否已经存在。若已经存在，输出：
```
XXXX has existed!
Press [C] to cover existed file; Press [S] to stop compressing.
```
并根据用户的输入决定覆盖或者保留。

在每次试图解压文件是调用`isInCurDir`判断，就解决了文件覆盖问题。
### 压缩包预览
+ 原文件为单个文件
    直接读入压缩文件头部信息的fileName并输出即可。
+ 原文件为文件夹
    根据我的设计原文件夹的所有子路径都以path形式，且以先根序写在了压缩文件内，因此不需要真正还原文件树，只需顺序读入路径信息。
    我构造了`entry`结构体来指导文件树形结构的输出：包括路径信息和前导空格个数信息。并通过`entry`栈来得到树形结构。
    + 如果栈顶元素是当前元素的直接父目录，则将当前元素前导空格数++，输出并入栈。
    + 如果栈顶元素不是是当前元素的直接父目录，则一直pop栈顶，直到栈顶元素是当前元素的直接父目录，将当前元素前导空格数++，输出并入栈。
    + 直到所有路径都得到遍历时结束。
## 开发环境与构建工具
+ 编辑器为windows10下的vscode (version1.17.1)
+ 编译器为`gcc version 11.2.0 (MinGW-W64 x86_64-posix-seh Sanders)`
+ 构建工具为非常简易的CmakeLists。（已上传）
+ 调试工具为vscode自带调试工具。
+ 最终编译为一个程序`main.exe`，运行方法详见README.md
## 性能测试
|测试样例|初始大小|压缩后大小|压缩率|压缩时间|解压时间|
|-------|---------|---------|------|--------|--------|
|testcase01EmptyFile|0 B|109 B|---------|16 ms|12 ms|
|testcase02NormalSingleFile|22.8 MB|16.7 MB|73.2%|829 ms|747 ms|
|testcase03XLargeSingleFile|1.02 GB|676 MB|66.3%|60.1 s|59.8 s|
|testcase4EmptyFolder|0 B|85 B|---------|10 ms|8 ms|
|testcase5NomalFolder|5.81 MB|4.05 MB|69.7%|771 ms|471 ms|
|testcase06SubFolders|437 MB|439 MB|100.4%|60.6 s|48.0 s|
|testcase07XlargeSubFolders|1.02 GB|665 MB|65.1%|59.9 s|57.1 s|
|testcase08Speed|613 MB|392 MB|63.9%|33.2 s|19.2 s|
|testcase09Ratio|421 MB|264 MB|62.7%|24.9 s|20.8 s|
|testcases|3.52 GB|2.40 GB |68.1%|243 s|216 s|
## 与其他压缩工具比较
选取`WinRAR`与`BandiZip`作为对照
+ 样例1：小文件`testcases\testcase02NormalSingleFile\1.txt`
  
    |压缩工具|初始大小|压缩率|压缩时间|
    |--------|--------|-----|-------|
    |SY-tar|1.89 MB|55.0%|133 ms|
    |WinRAR|1.89 MB|31.7%|不到1s|
    |BandiZip|1.89 MB|37.8%|不到1s|
+ 样例2：大文件`testcases\testcase08Speed\1.csv`

    |压缩工具|初始大小|压缩率|压缩时间|
    |--------|--------|-----|-------|
    |SY-tar|613 MB|63.9%|33.3 s|
    |WinRAR|613 MB|7.9%|10 s|
    |BandiZip|613 MB|11.6%|1 s|
+ 样例3：大文件`testcases\testcase09Ratio\1.csv`
  
    |压缩工具|初始大小|压缩率|压缩时间|
    |--------|--------|-----|-------|
    |SY-tar|421 MB|62.7%|26 s|
    |WinRAR|421 MB|11.5%|11 s|
    |BandiZip|421 MB|23.4%|2 s| 
+ 样例4：文件夹`testcases\testcase06SubFolders`
  
    |压缩工具|初始大小|压缩率|压缩时间|
    |--------|--------|-----|-------|
    |SY-tar|437 MB|100%|58 s|
    |WinRAR|437 MB|96.5%|14 s|
    |BandiZip|437 MB|96.5%|9 s|

产生这些区别的原因
+ 压缩率
   主要原因是算法原因：
    1. Huffman算法在字节频率分布严重不均时压缩表现较好，而在字节频率分布均匀时压缩表现很差。因为在字节频率严格均匀时，Huffman编码与等成编码的WPL一样大。而WinRAR与BandiZip采用的算法能避免压缩率极端情况下急剧上升。
    2. Huffman算法将字节作为最小单位，这可能导致它忽略多字节级别的重复特征。例如连续出现的相同字节，重复出现的高频单词等等。
   
   其次在我写的程序中，压缩文件的头部信息相对冗长，可能有少量不必要的信息。
+ 压缩时间
    1. I/O 原因
        使用了朴素的`std::fstream`进行输入输出，I/O速度上有明显提升空间。
    2. 算法原因
        Huffman算法逐字节处理，可以优化。而且解压时每个字节都需要跑一边Huffman树，时间代价较大。
## 遇到的问题与解决方案
+ 压缩时难以储存Huffman树。
    解决方法：储存字节频率，解压时在构建Huffman树。
+ 压缩文件可能因为最后一个字节没写满导致多余0位，解压时会出错。
    ```
    eg: 'a' 编码为00, 'b'编码为11。而文件最后一个字节为11110000
    此时有可能表示"bbaa", 也可能表示"bba",或者"bb".
    ```
    解决方法：解压时记录已经解压的字节个数，当等于字节总数时直接退出。
+ 压缩文件夹时需要往同一文件的不同位置写入
    解决方法：传递`std::streampos`类参数指导文件指针位移。
+ 解压时无法判断路径字符串代表文件或文件夹
    解决方法：解压时在代表文件的路径后写入`(char)254(char)254`作为文件类型提示符。
---
Produced By Shang-Yu
项目同步于<https://github.com/shnag-yu/SY-tar>





